{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c86313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import json\n",
    "sys.path.append('/home/kvulic/Vulic/cmos_toolbox_w_spike_sorter/')\n",
    "from src.cmos_plotter.Latency_calculator import *\n",
    "from src.utils.logger_functions import console\n",
    "from src.utils.metadata_functions import load_metadata_as_dataframe\n",
    "import logging\n",
    "logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac422ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_PATH = '...'\n",
    "PROCESSED_DATA_PATH = os.path.join(MAIN_PATH, f'Processed_data/')\n",
    "OUTPUT_PATH = os.path.join(MAIN_PATH,f'...')\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)\n",
    "\n",
    "filename = '...'\n",
    "\n",
    "SORTER_PATH = PROCESSED_DATA_PATH\n",
    "FULL_SORTER_PATH = os.path.join(SORTER_PATH,'Sorter_'+filename)\n",
    "\n",
    "PAIRINGS_PATH = os.path.join(MAIN_PATH, f'...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3edee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(os.path.join(PROCESSED_DATA_PATH, f'{filename[:-3]}_processed.pkl'), allow_pickle=True)\n",
    "spikes_extremum = pd.DataFrame(data['SPIKEMAT_EXTREMUM'])\n",
    "spikes = np.array([[int(row[0]), float(row[1]), float(row[2])] for row in data['SPIKEMAT']])\n",
    "a = 0\n",
    "area = filename.split('_')[1]\n",
    "data_te = np.load(os.path.join(PAIRINGS_PATH, f'{filename[:-3]}_processed_info_metrics.pkl'), allow_pickle=True)\n",
    "if 'validated_results' in data_te.keys():\n",
    "    console.info(f'Pairs from {filename} were already validated')\n",
    "if a ==0:\n",
    "    exp_duration = data_te['EXPERIMENT_DURATION']\n",
    "    te_unit_pairs = pd.DataFrame(data_te['mTE'])\n",
    "    pairings = te_unit_pairs\n",
    "    \n",
    "\n",
    "    with open(os.path.join(FULL_SORTER_PATH, 'wf_folder_curated/sparsity.json'), 'r') as file:\n",
    "        sorting_info = json.load(file)\n",
    "\n",
    "    unit_ids = sorting_info['unit_ids']\n",
    "\n",
    "    spikes, electrodes_pre_all, electrodes_post_all, pre_extremum_all, post_extremum_all, unit_pre_all, unit_post_all, lag_all = get_electrode_unit_info_te(data, pairings, area, unit_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd06c08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx in range(len(unit_pre_all)):\n",
    "    unit_pre = unit_pre_all[idx]\n",
    "    unit_post = unit_post_all[idx]\n",
    "    pre_extremum = pre_extremum_all[idx]\n",
    "    post_extremum = post_extremum_all[idx]\n",
    "    lag = lag_all[idx]\n",
    "    unit_to_el = data_te['UNIT_TO_EL']\n",
    "\n",
    "    lat = plot_latency_and_location_with_extremum_both_plots(OUTPUT_PATH, filename, lag, exp_duration, unit_to_el, pre_extremum, post_extremum, unit_pre, unit_post, unit_ids, spikes, spikes_extremum, extremum_output = post_extremum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea20125",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = plot_latency_and_location_with_extremum_both_plots(OUTPUT_PATH, filename, lag, exp_duration, unit_to_el, pre_extremum, post_extremum, unit_pre, unit_post, unit_ids, spikes, spikes_extremum, extremum_output = post_extremum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a99cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,3))\n",
    "plt.subplots_adjust(left=0., right=0.95, bottom=0.15, top=0.95)\n",
    "\n",
    "input_color = '#2bace2'\n",
    "output_color = '#f281b2'\n",
    "\n",
    "\n",
    "input = lat[lat['category'] == 'input']\n",
    "output = lat[lat['category'] == 'output']\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter(output['latency'], output['spike time'] / 1000, s=1, color=output_color, alpha=0.8)\n",
    "plt.scatter(input['latency'], input['spike time'] / 1000, s=1, color=input_color, alpha=0.8)\n",
    "plt.xlabel('Latency [ms]', fontsize=12)\n",
    "plt.ylabel('Experiment Time [s]', fontsize=12)\n",
    "plt.ylim(-0.5, 100)\n",
    "plt.xlim(-0.5, 6)\n",
    "\n",
    "ax.spines['left'].set_position(('outward', 5))\n",
    "ax.spines['bottom'].set_position(('outward', 5))\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.tick_params(axis='x', labelsize=12)\n",
    "ax.tick_params(axis='y', labelsize=12)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_PATH, f'Latency_plot_before_stimulation'), dpi=300, bbox_inches='tight')\n",
    "plt.savefig(os.path.join(OUTPUT_PATH, f'Latency_plot_before_stimulation.pdf'), dpi=300, bbox_inches='tight')\n",
    "plt.savefig(os.path.join(OUTPUT_PATH, f'Latency_plot_before_stimulation.svg'), dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6433ed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure and axes with specific padding\n",
    "fig, ax = plt.subplots(figsize=(4,3))\n",
    "\n",
    "latency_week_after = lat_after\n",
    "\n",
    "# Set space between axes and plot area\n",
    "plt.subplots_adjust(left=0., right=0.95, bottom=0.15, top=0.95)\n",
    "\n",
    "input_color = '#2bace2'\n",
    "output_color = '#f281b2'\n",
    "\n",
    "# Plot latency_before data\n",
    "\n",
    "input_week_after = latency_week_after[latency_week_after['category'] == 'input']\n",
    "output_week_after = latency_week_after[latency_week_after['category'] == 'output']\n",
    "\n",
    "# Use plt.scatter directly\n",
    "\n",
    "\n",
    "plt.scatter(output_week_after['latency'], output_week_after['spike time'] / 1000, s=1, color=output_color, alpha=0.8)\n",
    "plt.scatter(input_week_after['latency'], input_week_after['spike time'] / 1000, s=1, color=input_color, alpha=0.8)\n",
    "# Set labels\n",
    "plt.xlabel('Latency [ms]', fontsize=12)\n",
    "plt.ylabel('Experiment Time [s]', fontsize=12)\n",
    "plt.ylim(-0.50,100)\n",
    "plt.xlim(-0.5, 6)\n",
    "\n",
    "\n",
    "# Adjust spines to create space between axes and plot area\n",
    "ax.spines['left'].set_position(('outward', 5))\n",
    "ax.spines['bottom'].set_position(('outward', 5))\n",
    "\n",
    "# Turn off the top and right spines to match your example\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.tick_params(axis='x', labelsize=12)\n",
    "ax.tick_params(axis='y', labelsize=12)\n",
    "#plt.xticks(np.arange(0, 11, 2), fontsize = 12)\n",
    "#plt.yticks(np.arange(0, 400, 100), fontsize = 12)\n",
    "\n",
    "# Make the layout compact\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_PATH, f'Latency_plot_after_stimulation'), dpi=300, bbox_inches='tight')\n",
    "plt.savefig(os.path.join(OUTPUT_PATH, f'Latency_plot_after_stimulation.pdf'), dpi=300, bbox_inches='tight')\n",
    "plt.savefig(os.path.join(OUTPUT_PATH, f'Latency_plot_after_stimulation.svg'), dpi=300, bbox_inches='tight')\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99e2a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# I'm assuming you already have your three arrays: latency_before, latency_after, and latency_after_2\n",
    "\n",
    "# Create figure and axes with specific padding\n",
    "fig, ax = plt.subplots(figsize=(4,8))\n",
    "\n",
    "# Set space between axes and plot area\n",
    "plt.subplots_adjust(left=0., right=0.95, bottom=0.15, top=0.95)\n",
    "\n",
    "input_color = '#2bace2'\n",
    "output_color = '#f281b2'\n",
    "\n",
    "# Plot latency_before data\n",
    "input_before = lat_before[lat_before['category'] == 'input']\n",
    "output_before = lat_before[lat_before['category'] == 'output']\n",
    "\n",
    "# Use plt.scatter directly\n",
    "plt.scatter(input_before['latency'], input_before['spike time'] / 1000, s=7, color=input_color, alpha=0.8)\n",
    "plt.scatter(output_before['latency'], output_before['spike time'] / 1000, s=7, color=output_color, alpha=0.8)\n",
    "\n",
    "# Plot latency_after data (add 5 min = 300000 ms)\n",
    "input_after = lat_after[lat_after['category'] == 'input']\n",
    "output_after = lat_after[lat_after['category'] == 'output']\n",
    "\n",
    "plt.scatter(input_after['latency'], input_after['spike time'] / 1000+600, s=7, color=input_color, alpha=0.8)\n",
    "plt.scatter(output_after['latency'], output_after['spike time'] / 1000+600, s=7, color=output_color, alpha=0.8)\n",
    "\n",
    "\n",
    "\n",
    "# Set x-axis ticks to show only even numbers (0,2,4,6,8,10)\n",
    "plt.xticks(np.arange(0, 11, 2), fontsize = 18)\n",
    "\n",
    "\n",
    "# Set axis limits based on your data (mirroring your example image)\n",
    "#plt.xlim(-0.5, 10.5)\n",
    "#plt.ylim(-5, 105)\n",
    "\n",
    "# Set labels\n",
    "plt.xlabel('Latency (ms)', fontsize=16)\n",
    "plt.ylabel('Experiment Time (s)', fontsize=16)\n",
    "\n",
    "# Adjust spines to create space between axes and plot area\n",
    "ax.spines['left'].set_position(('outward', 5))\n",
    "ax.spines['bottom'].set_position(('outward', 5))\n",
    "\n",
    "# Turn off the top and right spines to match your example\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.tick_params(axis='x', labelsize=16)\n",
    "ax.tick_params(axis='y', labelsize=16)\n",
    "\n",
    "# Make the layout compact\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_PATH, f'Latency_plot_{filename[:-3]}_pair.png'), dpi=300, bbox_inches='tight')\n",
    "plt.savefig(os.path.join(OUTPUT_PATH, f'Latency_plot_{filename[:-3]}_pair.svg'), dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bee308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# I'm assuming you already have your three arrays: latency_before, latency_after, and latency_after_2\n",
    "\n",
    "# Create figure and axes with specific padding\n",
    "fig, ax = plt.subplots(figsize=(4,8))\n",
    "\n",
    "# Set space between axes and plot area\n",
    "plt.subplots_adjust(left=0., right=0.95, bottom=0.15, top=0.95)\n",
    "\n",
    "input_color = '#2bace2'\n",
    "output_color = '#f281b2'\n",
    "\n",
    "# Plot latency_before data\n",
    "input_before = latency_before[latency_before['category'] == 'input']\n",
    "output_before = latency_before[latency_before['category'] == 'output']\n",
    "\n",
    "# Use plt.scatter directly\n",
    "plt.scatter(input_before['latency'], input_before['spike time'] / 1000, s=7, color=input_color, alpha=0.8)\n",
    "plt.scatter(output_before['latency'], output_before['spike time'] / 1000, s=7, color=output_color, alpha=0.8)\n",
    "\n",
    "# Plot latency_after data (add 5 min = 300000 ms)\n",
    "input_after = latency_after[latency_after['category'] == 'input']\n",
    "output_after = latency_after[latency_after['category'] == 'output']\n",
    "\n",
    "plt.scatter(input_after['latency'], input_after['spike time'] / 1000+600, s=7, color=input_color, alpha=0.8)\n",
    "plt.scatter(output_after['latency'], output_after['spike time'] / 1000+600, s=7, color=output_color, alpha=0.8)\n",
    "\n",
    "# Plot latency_after_2 data (add 10 min = 600000 ms)\n",
    "input_after_2 = latency_after_2[latency_after_2['category'] == 'input']\n",
    "output_after_2 = latency_after_2[latency_after_2['category'] == 'output']\n",
    "\n",
    "plt.scatter(input_after_2['latency'], input_after_2['spike time'] / 1000+900, s=7, color=input_color, alpha=0.8)\n",
    "plt.scatter(output_after_2['latency'], output_after_2['spike time'] / 1000+900, s=7, color=output_color, alpha=0.8)\n",
    "\n",
    "# Set x-axis ticks to show only even numbers (0,2,4,6,8,10)\n",
    "plt.xticks(np.arange(0, 11, 2), fontsize = 18)\n",
    "\n",
    "\n",
    "# Set axis limits based on your data (mirroring your example image)\n",
    "#plt.xlim(-0.5, 10.5)\n",
    "#plt.ylim(-5, 105)\n",
    "\n",
    "# Set labels\n",
    "plt.xlabel('Latency (ms)', fontsize=16)\n",
    "plt.ylabel('Experiment Time (s)', fontsize=16)\n",
    "\n",
    "# Adjust spines to create space between axes and plot area\n",
    "ax.spines['left'].set_position(('outward', 5))\n",
    "ax.spines['bottom'].set_position(('outward', 5))\n",
    "\n",
    "# Turn off the top and right spines to match your example\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.tick_params(axis='x', labelsize=16)\n",
    "ax.tick_params(axis='y', labelsize=16)\n",
    "\n",
    "# Make the layout compact\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_PATH, f'Latency_plot_{filename[:-3]}_pair.png'), dpi=300, bbox_inches='tight')\n",
    "plt.savefig(os.path.join(OUTPUT_PATH, f'Latency_plot_{filename[:-3]}_pair.svg'), dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86bef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# I'm assuming you already have your three arrays: latency_before, latency_after, and latency_after_2\n",
    "# The code below shows how to plot them all on the same figure\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 8))\n",
    "\n",
    "# Colors for consistency\n",
    "input_color = '#2bace2'\n",
    "output_color = '#f281b2'\n",
    "\n",
    "# Plot latency_before data\n",
    "input_before = latency_before[latency_before['category'] == 'input']\n",
    "output_before = latency_before[latency_before['category'] == 'output']\n",
    "ax.scatter(output_before['latency'], output_before['spike time'] / 1000, s=7, color=output_color, alpha=0.7)\n",
    "ax.scatter(input_before['latency'], input_before['spike time'] / 1000, s=7, color=input_color, alpha=0.7)\n",
    "\n",
    "# Plot latency_after data (add 5 min = 300000 ms)\n",
    "input_after = latency_after[latency_after['category'] == 'input']\n",
    "output_after = latency_after[latency_after['category'] == 'output']\n",
    "ax.scatter(output_after['latency'], output_after['spike time'] / 1000 + 600, s=7,  color=output_color, alpha=0.7)\n",
    "ax.scatter(input_after['latency'], input_after['spike time'] / 1000 + 600, s=7, color=input_color, alpha=0.7)\n",
    "\n",
    "# Plot latency_after_2 data (add 10 min = 600000 ms)\n",
    "input_after_2 = latency_after_2[latency_after_2['category'] == 'input']\n",
    "output_after_2 = latency_after_2[latency_after_2['category'] == 'output']\n",
    "ax.scatter(output_after_2['latency'], output_after_2['spike time'] / 1000 + 900, s=7, color=output_color, alpha=0.7)\n",
    "ax.scatter(input_after_2['latency'], input_after_2['spike time'] / 1000 + 900, s=7, color=input_color, alpha=0.7)\n",
    "\n",
    "# Add horizontal lines to separate the periods\n",
    "y_min, y_max = ax.get_ylim()\n",
    "ax.axhline(y=300, color='gray', linestyle='--', alpha=0.5)  # Line at 5 min = 300 sec\n",
    "ax.axhline(y=600, color='gray', linestyle='--', alpha=0.5)  # Line at 10 min = 600 sec\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('Latency (ms)')\n",
    "ax.set_ylabel('Time (seconds)')\n",
    "ax.set_title(f\"Source {unit_pre} to Target {unit_post}\")\n",
    "\n",
    "# Create a custom legend to avoid duplicates\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "\n",
    "# Add annotations to identify time periods\n",
    "ax.text(ax.get_xlim()[1] * 0.95, 150, 'Before', horizontalalignment='right')\n",
    "ax.text(ax.get_xlim()[1] * 0.95, 750, 'After', horizontalalignment='right')\n",
    "ax.text(ax.get_xlim()[1] * 0.95, 1050, 'After_2', horizontalalignment='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8908386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "def calculate_synaptic_probability(data, time_bin_size=30):\n",
    "    \"\"\"\n",
    "    Calculate synaptic probability over time bins.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: Dictionary containing 'lag' and 'latency_extremum'\n",
    "    - time_bin_size: Size of time bins in ms (default: 30)\n",
    "    \n",
    "    Returns:\n",
    "    - time_bins: Array of time bin centers\n",
    "    - probabilities: Array of synaptic probabilities for each time bin\n",
    "    - prob_changes: Array of changes in probability between consecutive time bins\n",
    "    \"\"\"\n",
    "    lag = data['lag']\n",
    "    latency = data['latency_extremum']\n",
    "    \n",
    "    # Extract all spike times\n",
    "    all_spike_times = latency['spike time']\n",
    "    \n",
    "    # Determine the range of time bins\n",
    "    min_time = np.min(all_spike_times)\n",
    "    max_time = np.max(all_spike_times)\n",
    "    \n",
    "    # Create time bins\n",
    "    time_edges = np.arange(min_time, max_time + time_bin_size, time_bin_size)\n",
    "    time_bins = (time_edges[:-1] + time_edges[1:]) / 2  # Centers of bins\n",
    "    \n",
    "    probabilities = []\n",
    "    \n",
    "    # For each time bin, calculate synaptic probability\n",
    "    for i in range(len(time_bins)):\n",
    "        bin_start = time_edges[i]\n",
    "        bin_end = time_edges[i+1]\n",
    "        \n",
    "        # Filter latency data for current time bin\n",
    "        time_mask = (all_spike_times >= bin_start) & (all_spike_times < bin_end)\n",
    "        bin_latency = latency[time_mask]\n",
    "        \n",
    "        if len(bin_latency) == 0:\n",
    "            # No spikes in this bin\n",
    "            probabilities.append(0)\n",
    "            continue\n",
    "        \n",
    "        # Filter for output spikes\n",
    "        data_output = bin_latency[bin_latency['category'] == 'output']\n",
    "        \n",
    "        # Filter for latency within lag ± 1 ms\n",
    "        latency_filtered = data_output[(data_output['latency'] >= lag - 1) & \n",
    "                                     (data_output['latency'] <= lag + 1)]\n",
    "        \n",
    "        # Get input spikes in this bin\n",
    "        input_spikes = bin_latency[bin_latency['category'] == 'input']\n",
    "        input_spike_counts = len(input_spikes)\n",
    "        \n",
    "        if input_spike_counts == 0:\n",
    "            # No input spikes in this bin\n",
    "            probabilities.append(0)\n",
    "            continue\n",
    "        \n",
    "        # Count output spikes that correspond to input spikes\n",
    "        output_spike_counts = np.sum(np.isin(latency_filtered['input spike'], \n",
    "                                          input_spikes['input spike']))\n",
    "        \n",
    "        # Calculate probability\n",
    "        probability = output_spike_counts / input_spike_counts\n",
    "        probabilities.append(probability)\n",
    "    \n",
    "    probabilities = np.array(probabilities)\n",
    "    \n",
    "    # Calculate changes in probability\n",
    "    prob_changes = np.diff(probabilities, prepend=probabilities[0])\n",
    "    \n",
    "    return time_bins, probabilities, prob_changes\n",
    "\n",
    "def plot_synaptic_probability(time_bins, probabilities, prob_changes):\n",
    "    \"\"\"Plot synaptic probability over time and its change.\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "    \n",
    "    # Plot synaptic probability over time\n",
    "    ax1.plot(time_bins, probabilities, 'b-', linewidth=2)\n",
    "    ax1.set_ylabel('Synaptic Probability')\n",
    "    ax1.set_title('Synaptic Probability Over Time')\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot change in synaptic probability over time\n",
    "    ax2.plot(time_bins, prob_changes, 'r-', linewidth=2)\n",
    "    ax2.set_xlabel('Time (ms)')\n",
    "    ax2.set_ylabel('Change in Probability')\n",
    "    ax2.set_title('Change in Synaptic Probability Over Time')\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eccc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#res[31]['latency_extremum']\n",
    "data = res[31]\n",
    "# Calculate synaptic probability over time\n",
    "time_bins, probabilities, prob_changes = calculate_synaptic_probability(data, time_bin_size=25000)\n",
    "\n",
    "# Plot the results\n",
    "plot_synaptic_probability(time_bins, probabilities, prob_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67764cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "def calculate_synaptic_probability(latency, lag, time_bin_size=30):\n",
    "    \"\"\"\n",
    "    Calculate synaptic probability over time bins.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: Dictionary containing 'lag' and 'latency_extremum'\n",
    "    - time_bin_size: Size of time bins in ms (default: 30)\n",
    "    \n",
    "    Returns:\n",
    "    - time_bins: Array of time bin centers (in seconds)\n",
    "    - probabilities: Array of synaptic probabilities for each time bin\n",
    "    - prob_changes: Array of changes in probability between consecutive time bins\n",
    "    \"\"\"\n",
    "    # Extract all spike times\n",
    "    all_spike_times = latency['spike time']\n",
    "    \n",
    "    # Determine the range of time bins\n",
    "    min_time = np.min(all_spike_times)\n",
    "    max_time = np.max(all_spike_times)\n",
    "    \n",
    "    # Create time bins\n",
    "    time_edges = np.arange(min_time, max_time + time_bin_size, time_bin_size)\n",
    "    time_bins = (time_edges[:-1] + time_edges[1:]) / 2  # Centers of bins\n",
    "    \n",
    "    # Convert time bins from ms to seconds\n",
    "    time_bins_seconds = time_bins / 1000.0\n",
    "    \n",
    "    probabilities = []\n",
    "    \n",
    "    # For each time bin, calculate synaptic probability\n",
    "    for i in range(len(time_bins)):\n",
    "        bin_start = time_edges[i]\n",
    "        bin_end = time_edges[i+1]\n",
    "        \n",
    "        # Filter latency data for current time bin\n",
    "        time_mask = (all_spike_times >= bin_start) & (all_spike_times < bin_end)\n",
    "        bin_latency = latency[time_mask]\n",
    "        \n",
    "        if len(bin_latency) == 0:\n",
    "            # No spikes in this bin\n",
    "            probabilities.append(0)\n",
    "            continue\n",
    "        \n",
    "        # Filter for output spikes\n",
    "        data_output = bin_latency[bin_latency['category'] == 'output']\n",
    "        \n",
    "        # Filter for latency within lag ± 1 ms\n",
    "        latency_filtered = data_output[(data_output['latency'] >= lag - 1) & \n",
    "                                     (data_output['latency'] <= lag + 1)]\n",
    "        \n",
    "        # Get input spikes in this bin\n",
    "        input_spikes = bin_latency[bin_latency['category'] == 'input']\n",
    "        input_spike_counts = len(input_spikes)\n",
    "        \n",
    "        if input_spike_counts == 0:\n",
    "            # No input spikes in this bin\n",
    "            probabilities.append(0)\n",
    "            continue\n",
    "        \n",
    "        # Count output spikes that correspond to input spikes\n",
    "        output_spike_counts = np.sum(np.isin(latency_filtered['input spike'], \n",
    "                                          input_spikes['input spike']))\n",
    "        \n",
    "        # Calculate probability\n",
    "        probability = output_spike_counts / input_spike_counts\n",
    "        probabilities.append(probability)\n",
    "    \n",
    "    probabilities = np.array(probabilities)\n",
    "    \n",
    "    # Calculate changes in probability\n",
    "    prob_changes = np.diff(probabilities, prepend=probabilities[0])\n",
    "    \n",
    "    return time_bins_seconds, probabilities, prob_changes\n",
    "\n",
    "def plot_synaptic_probability(time_bins_seconds, probabilities, prob_changes):\n",
    "    \"\"\"Plot synaptic probability over time and its change.\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "    \n",
    "    # Plot synaptic probability over time\n",
    "    ax1.plot(time_bins_seconds, probabilities, 'b-', linewidth=2)\n",
    "    ax1.set_ylabel('Synaptic Probability')\n",
    "    ax1.set_title('Synaptic Probability Over Time')\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot change in synaptic probability over time\n",
    "    ax2.plot(time_bins_seconds, prob_changes, 'r-', linewidth=2)\n",
    "    ax2.set_xlabel('Time (s)')\n",
    "    ax2.set_ylabel('Change in Probability')\n",
    "    ax2.set_title('Change in Synaptic Probability Over Time')\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91687277",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['latency_extremum']\n",
    "#filter only cateogry output\n",
    "latency = latency_after\n",
    "latency = latency[latency['category'] == 'output']\n",
    "#calculate mean latency\n",
    "mean_latency = np.mean(latency['latency'])\n",
    "median_latency = np.median(latency['latency'])\n",
    "mean_latency, median_latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d6e3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_te.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7f0637",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_probabilities = []\n",
    "all_prob_changes = []\n",
    "for row in data_te['validated_results']:\n",
    "    if row['validation'] == 'good':\n",
    "        latency = row['latency_extremum']\n",
    "        lag = row['lag']\n",
    "        time_bins, probabilities, prob_changes = calculate_synaptic_probability(latency, lag, time_bin_size=25000)\n",
    "        all_probabilities.append(probabilities)\n",
    "        all_prob_changes.append(prob_changes)\n",
    "\n",
    "all_probabilities = np.array(all_probabilities)\n",
    "all_prob_changes = np.array(all_prob_changes)\n",
    "#plot mean of all probabilities\n",
    "mean_probabilities = np.mean(all_probabilities, axis=0)\n",
    "mean_prob_changes = np.mean(all_prob_changes, axis=0)\n",
    "#plot mean of all probabilities\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "# Plot synaptic probability over time\n",
    "ax1.plot(time_bins, mean_probabilities, 'b-', linewidth=2)\n",
    "ax1.set_ylabel('Synaptic Probability')\n",
    "ax1.set_title('Mean Synaptic Probability Over Time')\n",
    "ax1.grid(True)\n",
    "# Plot change in synaptic probability over time\n",
    "ax2.plot(time_bins, mean_prob_changes, 'r-', linewidth=2)\n",
    "ax2.set_xlabel('Time (ms)')\n",
    "ax2.set_ylabel('Change in Probability')\n",
    "ax2.set_title('Mean Change in Synaptic Probability Over Time')\n",
    "ax2.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e380e133",
   "metadata": {},
   "outputs": [],
   "source": [
    "#res[31]['latency_extremum']\n",
    "\n",
    "# Calculate synaptic probability over time\n",
    "time_bins, probabilities, prob_changes = calculate_synaptic_probability(latency_after, median_latency,  time_bin_size=100000)\n",
    "\n",
    "# Plot the results\n",
    "plot_synaptic_probability(time_bins, probabilities, prob_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6ef7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def calculate_synaptic_probability(latency, lag, time_bin_size=30):\n",
    "    \"\"\"\n",
    "    Calculate synaptic probability over time bins.\n",
    "    \n",
    "    Parameters:\n",
    "    - latency: Dictionary containing 'spike time' and other data\n",
    "    - lag: The lag value\n",
    "    - time_bin_size: Size of time bins in ms (default: 30)\n",
    "    \n",
    "    Returns:\n",
    "    - time_bins: Array of time bin centers (in seconds)\n",
    "    - probabilities: Array of synaptic probabilities for each time bin\n",
    "    - prob_changes: Array of changes in probability between consecutive time bins\n",
    "    \"\"\"\n",
    "    # Extract all spike times\n",
    "    all_spike_times = latency['spike time']\n",
    "    \n",
    "    # Determine the range of time bins\n",
    "    min_time = np.min(all_spike_times)\n",
    "    max_time = np.max(all_spike_times)\n",
    "    \n",
    "    # Create time bins\n",
    "    time_edges = np.arange(min_time, max_time + time_bin_size, time_bin_size)\n",
    "    time_bins = (time_edges[:-1] + time_edges[1:]) / 2  # Centers of bins\n",
    "    \n",
    "    # Convert time bins from ms to seconds\n",
    "    time_bins_seconds = time_bins / 1000.0\n",
    "    \n",
    "    probabilities = []\n",
    "    \n",
    "    # For each time bin, calculate synaptic probability\n",
    "    for i in range(len(time_bins)):\n",
    "        bin_start = time_edges[i]\n",
    "        bin_end = time_edges[i+1]\n",
    "        \n",
    "        # Filter latency data for current time bin\n",
    "        time_mask = (all_spike_times >= bin_start) & (all_spike_times < bin_end)\n",
    "        bin_latency = latency[time_mask]\n",
    "        \n",
    "        if len(bin_latency) == 0:\n",
    "            # No spikes in this bin\n",
    "            probabilities.append(0)\n",
    "            continue\n",
    "        \n",
    "        # Filter for output spikes\n",
    "        data_output = bin_latency[bin_latency['category'] == 'output']\n",
    "        \n",
    "        # Filter for latency within lag ± 1 ms\n",
    "        latency_filtered = data_output[(data_output['latency'] >= lag - 1) & \n",
    "                                     (data_output['latency'] <= lag + 1)]\n",
    "        \n",
    "        # Get input spikes in this bin\n",
    "        input_spikes = bin_latency[bin_latency['category'] == 'input']\n",
    "        input_spike_counts = len(input_spikes)\n",
    "        \n",
    "        if input_spike_counts == 0:\n",
    "            # No input spikes in this bin\n",
    "            probabilities.append(0)\n",
    "            continue\n",
    "        \n",
    "        # Count output spikes that correspond to input spikes\n",
    "        output_spike_counts = np.sum(np.isin(latency_filtered['input spike'], \n",
    "                                          input_spikes['input spike']))\n",
    "        \n",
    "        # Calculate probability\n",
    "        probability = output_spike_counts / input_spike_counts\n",
    "        probabilities.append(probability)\n",
    "    \n",
    "    probabilities = np.array(probabilities)\n",
    "    \n",
    "    # Calculate changes in probability\n",
    "    prob_changes = np.diff(probabilities, prepend=probabilities[0])\n",
    "    \n",
    "    return time_bins_seconds, probabilities, prob_changes\n",
    "\n",
    "# Approach 1: Using interpolation to align all time series to a common time axis\n",
    "def interpolate_and_plot(data_te):\n",
    "    all_time_bins = []\n",
    "    all_probabilities = []\n",
    "    all_prob_changes = []\n",
    "    \n",
    "    # First pass: collect all data\n",
    "    for row in data_te['validated_results']:\n",
    "        if row['validation'] == 'good':\n",
    "            latency = row['latency_extremum']\n",
    "            lag = row['lag']\n",
    "            time_bins, probabilities, prob_changes = calculate_synaptic_probability(latency, lag, time_bin_size=25000)\n",
    "            all_time_bins.append(time_bins)\n",
    "            all_probabilities.append(probabilities)\n",
    "            all_prob_changes.append(prob_changes)\n",
    "    \n",
    "    # Find global time range\n",
    "    min_time = min([np.min(tb) for tb in all_time_bins])\n",
    "    max_time = max([np.max(tb) for tb in all_time_bins])\n",
    "    \n",
    "    # Create a common time axis with a reasonable number of points\n",
    "    num_points = 100  # Adjust as needed\n",
    "    common_time_axis = np.linspace(min_time, max_time, num_points)\n",
    "    \n",
    "    # Interpolate each dataset to the common time axis\n",
    "    interpolated_probs = []\n",
    "    interpolated_changes = []\n",
    "    \n",
    "    for i in range(len(all_time_bins)):\n",
    "        # Create interpolation functions\n",
    "        f_prob = interp1d(all_time_bins[i], all_probabilities[i], \n",
    "                          bounds_error=False, fill_value=0)\n",
    "        f_change = interp1d(all_time_bins[i], all_prob_changes[i], \n",
    "                           bounds_error=False, fill_value=0)\n",
    "        \n",
    "        # Interpolate to common time axis\n",
    "        interpolated_probs.append(f_prob(common_time_axis))\n",
    "        interpolated_changes.append(f_change(common_time_axis))\n",
    "    \n",
    "    # Convert to numpy arrays now that they all have the same shape\n",
    "    interpolated_probs = np.array(interpolated_probs)\n",
    "    interpolated_changes = np.array(interpolated_changes)\n",
    "    \n",
    "    # Calculate mean\n",
    "    mean_probabilities = np.mean(interpolated_probs, axis=0)\n",
    "    mean_prob_changes = np.mean(interpolated_changes, axis=0)\n",
    "    \n",
    "    # Plot results\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "    \n",
    "    # Plot synaptic probability over time\n",
    "    ax1.plot(common_time_axis, mean_probabilities, 'b-', linewidth=2)\n",
    "    ax1.set_ylabel('Synaptic Probability')\n",
    "    ax1.set_title('Mean Synaptic Probability Over Time')\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot change in synaptic probability over time\n",
    "    ax2.plot(common_time_axis, mean_prob_changes, 'r-', linewidth=2)\n",
    "    ax2.set_xlabel('Time (s)')\n",
    "    ax2.set_ylabel('Change in Probability')\n",
    "    ax2.set_title('Mean Change in Synaptic Probability Over Time')\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Approach 2: Alternative method using masking (useful if interpolation isn't appropriate)\n",
    "def mask_and_plot(data_te):\n",
    "    all_data = []\n",
    "    \n",
    "    # Collect all data with their time bins\n",
    "    for row in data_te['validated_results']:\n",
    "        if row['validation'] == 'good':\n",
    "            latency = row['latency_extremum']\n",
    "            lag = row['lag']\n",
    "            time_bins, probabilities, prob_changes = calculate_synaptic_probability(latency, lag, time_bin_size=25000)\n",
    "            all_data.append((time_bins, probabilities, prob_changes))\n",
    "    \n",
    "    # Find common time range\n",
    "    min_time = max([np.min(d[0]) for d in all_data])  # Latest start time\n",
    "    max_time = min([np.max(d[0]) for d in all_data])  # Earliest end time\n",
    "    \n",
    "    # Create time bins within the common range\n",
    "    bin_size = 0.025  # 25ms in seconds\n",
    "    common_bins = np.arange(min_time, max_time + bin_size, bin_size)\n",
    "    \n",
    "    # Initialize arrays for summing\n",
    "    sum_probs = np.zeros(len(common_bins))\n",
    "    sum_changes = np.zeros(len(common_bins))\n",
    "    counts = np.zeros(len(common_bins))\n",
    "    \n",
    "    # Process each dataset\n",
    "    for time_bins, probs, changes in all_data:\n",
    "        # Find indices that fall within common range\n",
    "        valid_indices = (time_bins >= min_time) & (time_bins <= max_time)\n",
    "        \n",
    "        # Get valid data\n",
    "        valid_times = time_bins[valid_indices]\n",
    "        valid_probs = probs[valid_indices]\n",
    "        valid_changes = changes[valid_indices]\n",
    "        \n",
    "        # Assign to nearest bin in common_bins\n",
    "        for t, p, c in zip(valid_times, valid_probs, valid_changes):\n",
    "            # Find closest bin\n",
    "            bin_idx = np.argmin(np.abs(common_bins - t))\n",
    "            \n",
    "            # Add to sums\n",
    "            sum_probs[bin_idx] += p\n",
    "            sum_changes[bin_idx] += c\n",
    "            counts[bin_idx] += 1\n",
    "    \n",
    "    # Calculate means, avoiding division by zero\n",
    "    mask = counts > 0\n",
    "    mean_probs = np.zeros_like(sum_probs)\n",
    "    mean_changes = np.zeros_like(sum_changes)\n",
    "    \n",
    "    mean_probs[mask] = sum_probs[mask] / counts[mask]\n",
    "    mean_changes[mask] = sum_changes[mask] / counts[mask]\n",
    "    \n",
    "    # Plot results\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "    \n",
    "    # Plot synaptic probability over time\n",
    "    ax1.plot(common_bins, mean_probs, 'b-', linewidth=2)\n",
    "    ax1.set_ylabel('Synaptic Probability')\n",
    "    ax1.set_title('Mean Synaptic Probability Over Time')\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot change in synaptic probability over time\n",
    "    ax2.plot(common_bins, mean_changes, 'r-', linewidth=2)\n",
    "    ax2.set_xlabel('Time (s)')\n",
    "    ax2.set_ylabel('Change in Probability')\n",
    "    ax2.set_title('Mean Change in Synaptic Probability Over Time')\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7726de1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "interpolate_and_plot(data_te)  # Use this approach if interpolation is appropriate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26b575e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_and_plot(data_te)         # Use this approach if you prefer binning without interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1d687b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
