{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/kvulic/Vulic/cmos_toolbox_w_spike_sorter/')\n",
    "from src.utils.metadata_functions import load_metadata_as_dataframe\n",
    "import logging\n",
    "logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from src.cmos_plotter import Waveform_plotter as wp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_PATH = '...'\n",
    "with open(os.path.join(MAIN_PATH, 'Results/combined_unit_metrics.pkl'), 'rb') as f:\n",
    "    data = pd.read_pickle(f)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and merge waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = pd.DataFrame()\n",
    "b=0\n",
    "for filename in data.filename.unique():\n",
    "    try:\n",
    "        filepath = os.path.join(MAIN_PATH, f'Sorters/Sorter_{filename}/wf_folder_curated/waveform_metrics_output')\n",
    "        df = wp.load_and_merge_waveforms(filepath, filename)\n",
    "        if df is not None:\n",
    "            all_dfs = pd.concat([all_dfs, df], axis=0, ignore_index=True)\n",
    "        \n",
    "    except Exception as e:\n",
    "        b+=1\n",
    "        print(f'Error with {filename}: {e}')\n",
    "        continue\n",
    "print(\"Number of errors:\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Waveform metrics merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(all_dfs, open(os.path.join(MAIN_PATH, 'Results/waveforms_all.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = pd.DataFrame()\n",
    "b=0\n",
    "for filename in data.filename.unique():\n",
    "    try:\n",
    "    #if filename == 'ID1103_N10_DIV17_DATE20240419_0915_spontaneous_CTRL.raw.h5':\n",
    "        filepath = os.path.join(MAIN_PATH, f'Sorters/Sorter_{filename}/wf_folder_curated/waveform_metrics_output')\n",
    "        #print(filename)\n",
    "        # Load and process waveform metrics\n",
    "        df = wp.load_and_process_waveform_metrics(filepath, filename)\n",
    "        if df is not None:\n",
    "            parent_folder = os.path.dirname(filepath)  # Get the parent folder of filepath\n",
    "            with open(os.path.join(parent_folder, 'sparsity.json'), 'rb') as f:\n",
    "                unit_ids = json.load(f)\n",
    "            unit_ids = list(map(int, unit_ids['unit_id_to_channel_ids'].keys()))\n",
    "            #print(unit_ids)\n",
    "            df['unit_index'] = df['unit_id'].map(lambda x: unit_ids.index(x) if x in unit_ids else None)\n",
    "            #print(df['unit_index'], df['unit_id'])\n",
    "            #all_dfs.append(df)\n",
    "            all_dfs = pd.concat([all_dfs, df], axis=0, ignore_index=True)\n",
    "        \n",
    "    except Exception as e:\n",
    "        b+=1\n",
    "        print(f'Error with {filename}: {e}')\n",
    "        continue\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_plot = [\n",
    "    'amplitude uV', \n",
    "    'peak_to_trough_duration', \n",
    "    'peak_trough_ratio', \n",
    "    'repolarization_slope', \n",
    "    'recovery_slope',\n",
    "    'half_width'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to plot based on your screenshot\n",
    "columns_to_plot = [\n",
    "    'peak_to_trough_duration', \n",
    "    'peak_trough_ratio', \n",
    "    'repolarization_slope', \n",
    "    'recovery_slope', \n",
    "    'amplitude uV',\n",
    "    'half_width'\n",
    "]\n",
    "\n",
    "# Define custom titles and labels with proper units\n",
    "custom_titles = {\n",
    "    'peak_to_trough_duration': 'Peak-to-Trough Duration [ms]',\n",
    "    'peak_trough_ratio': 'Peak-to-Trough Ratio',\n",
    "    'repolarization_slope': 'Repolarization Slope',\n",
    "    'recovery_slope': 'Recovery Slope',\n",
    "    'amplitude uV': 'Amplitude [Î¼V]',  # Corrected with proper micro symbol\n",
    "    'half_width': 'Half Width [ms]'\n",
    "}\n",
    "\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15, 10))\n",
    "axes = axes.flatten()  # Flatten the 2D array of axes\n",
    "\n",
    "# Set the style\n",
    "plt.style.use('default')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Color for all distributions\n",
    "color = 'dimgray'\n",
    "\n",
    "# Create histograms for each column\n",
    "for i, column in enumerate(columns_to_plot):\n",
    "    if i < len(axes):\n",
    "        # Create histogram with step-like edges and fill\n",
    "        # First, calculate the histogram data\n",
    "        hist_data = all_waveforms[column].dropna()\n",
    "        total_count = len(hist_data)  # Total number of rows for percentage calculation\n",
    "        print (f\"Total count for {column}: {total_count}\")\n",
    "        \n",
    "        # Determine appropriate number of bins based on data\n",
    "        if column == 'amplitude uV':\n",
    "            bins = np.linspace(0, 4000, 30)\n",
    "        elif column == 'peak_trough_ratio':\n",
    "            bins = np.linspace(0, 2.01, 30)\n",
    "        elif column == 'half_width':\n",
    "            bins = 20\n",
    "        else:\n",
    "            bins = 30  # Default number of bins\n",
    "            \n",
    "        # Calculate histogram values\n",
    "        hist, bin_edges = np.histogram(hist_data, bins=bins)\n",
    "        # Convert to percentage of total rows\n",
    "        hist = (hist / total_count) * 100\n",
    "        \n",
    "        # Plot the histogram as a step-filled area\n",
    "        axes[i].fill_between(\n",
    "            bin_edges[:-1], \n",
    "            hist, \n",
    "            step=\"post\", \n",
    "            alpha=0.5, \n",
    "            color=color\n",
    "        )\n",
    "        \n",
    "        # Add the step outline\n",
    "        axes[i].step(\n",
    "            bin_edges[:-1], \n",
    "            hist, \n",
    "            where='post', \n",
    "            color=color, \n",
    "            linewidth=1.5\n",
    "        )\n",
    "        \n",
    "        # Add a KDE curve\n",
    "        kde = sns.kdeplot(\n",
    "            data=hist_data, \n",
    "            ax=axes[i],\n",
    "            color=color,\n",
    "            linewidth=2.5,\n",
    "            common_norm=False,\n",
    "            bw_adjust=1,  # Adjust bandwidth for smoother curve\n",
    "        )\n",
    "        \n",
    "        # Scale KDE to match histogram percentage\n",
    "        for line in axes[i].get_lines():\n",
    "            ydata = line.get_ydata()\n",
    "            # Scale to percentage of rows\n",
    "            max_hist_val = hist.max() if len(hist) > 0 else 1\n",
    "            line.set_ydata(ydata * 100 / ydata.max() * max_hist_val / 100)\n",
    "        \n",
    "        if column == 'amplitude uV':\n",
    "            # Set x-axis limits for amplitude\n",
    "            axes[i].set_xlim(0, 4000)\n",
    "        if column == 'peak_trough_ratio':\n",
    "            # Set x-axis limits for peak-to-trough ratio\n",
    "            axes[i].set_xlim(0, 2.01)\n",
    "            \n",
    "        # Use custom titles with units\n",
    "        axes[i].set_title(custom_titles[column], fontsize=18)\n",
    "        axes[i].set_xlabel(custom_titles[column], fontsize=16)\n",
    "        axes[i].set_ylabel('Units [%]', fontsize=16)\n",
    "\n",
    "        axes[i].tick_params(axis='both', labelsize=16)\n",
    "        \n",
    "        # Remove top and right spines\n",
    "        #sns.despine(ax=axes[i])\n",
    "        \n",
    "        # Add grid lines only for y-axis\n",
    "        #axes[i].grid(axis='y', linestyle='-', alpha=0.7)\n",
    "        axes[i].grid(True, linestyle=':', alpha=0.7) \n",
    "\n",
    "# If there are unused subplots, hide them\n",
    "for j in range(len(columns_to_plot), len(axes)):\n",
    "    axes[j].set_visible(False)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.4)\n",
    "\n",
    "# Save the figure if needed\n",
    "plt.savefig(os.path.join(MAIN_PATH,'Results/waveform_distributions_new.png'), dpi=300, bbox_inches='tight')\n",
    "plt.savefig(os.path.join(MAIN_PATH,'Results/waveform_distribution_new.pdf'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
